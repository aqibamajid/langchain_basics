{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For nicer chat output \n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get OpenAI API key\n",
    "\n",
    "from src.paths import PARENT_DIR\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "import openai \n",
    "\n",
    "load_dotenv(PARENT_DIR / '.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test connection\n",
    "\n",
    "3 Roles in chat completion \n",
    "https://platform.openai.com/docs/guides/text-generation/chat-completions-api\n",
    "\n",
    "1) System - Optional, to tell the assistant how to behave \n",
    "2) User - you! i.e. the end user \n",
    "3) Assistant - whatever model you've selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test chat message \n",
    "\n",
    "pilot_message = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\"role\": \"user\",\n",
    "                \"content\": \"Hello, just testing if this api connection is working ok! Can you confirm you're receiving this message?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-98E9XHSpPik5nKtFlm8lJhTYwVqVt at 0x1287c268> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"message\": {\n",
       "        \"content\": \"Hello! Yes, I can confirm that I have received your message. Is there anything else you would like to test or ask about?\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1711748055,\n",
       "  \"id\": \"chatcmpl-98E9XHSpPik5nKtFlm8lJhTYwVqVt\",\n",
       "  \"model\": \"gpt-3.5-turbo-0125\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"system_fingerprint\": \"fp_3bc1b5746c\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 27,\n",
       "    \"prompt_tokens\": 28,\n",
       "    \"total_tokens\": 55\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See full output\n",
    "pilot_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! Yes, I can confirm that I have received your message. Is there anything else you would like to test or ask about?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See reply only ! \n",
    "\n",
    "pilot_message[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using langchain - legacy callback\n",
    "\n",
    "[Legacy_calls](https://python.langchain.com/docs/modules/model_io/chat/quick_start#legacy-__call__)\n",
    "\n",
    "Using langchain, the code becomes more 'tidy', when we want to extract messages from the assistant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new langchain version \n",
    "\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ChatOpenAI object. Assign to chat.\n",
    "chat = ChatOpenAI(model='gpt-3.5-turbo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain as lc \n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# HumanMessage is like openAI's 'user' role, and systemMessage is like 'system' role "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define : \n",
    "\n",
    "- system_message : Telling the assistant what context it's being used in, this will shape it's replies\n",
    "\n",
    "- data_brief : Explaining the data being analysed\n",
    "\n",
    "- task_request : Asking specific question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an analyst working for the government, tasked with analysing smoking behaviours, with the aim of creating government policy to decrease smoking.\"\n",
    "\n",
    "data_brief = \"\"\"\n",
    "We have some survey data on smoking habits from the UK. The data set can be used for analyzing the demographic characteristics of smokers and types of tobacco consumed.\n",
    "\n",
    "A data frame with 1691 observations on the following 12 variables: \n",
    "\n",
    "1) 'gender' (string) : Gender with levels Female and Male.\n",
    "2) 'age' (numeric) : Age\n",
    "3) 'marital_status' (string) : Marital status with levels Divorced, Married, Separated, Single and Widowed.\n",
    "4) 'highest_qualification' (string) : Highest education level with levels A Levels, Degree, GCSE/CSE, GCSE/O Level, Higher/Sub Degree, No Qualification, ONC/BTEC and Other/Sub Degree\n",
    "5) 'nationality' (string) : Nationality with levels British, English, Irish, Scottish, Welsh, Other, Refused and Unknown.\n",
    "6) 'ethnicity' (string) : Ethnicity with levels Asian, Black, Chinese, Mixed, White and Refused Unknown.\n",
    "7) 'gross_income' (string) : Gross income with levels Under 2,600, 2,600 to 5,200, 5,200 to 10,400, 10,400 to 15,600, 15,600 to 20,800, 20,800 to 28,600, 28,600 to 36,400, Above 36,400, Refused and Unknown.\n",
    "8) 'region' (string) : Region with levels London, Midlands & East Anglia, Scotland, South East, South West, The North and Wales\n",
    "9) 'smoke' (boolean) : Smoking status with levels No and Yes\n",
    "10) 'amt_weekends' (integer) : Number of cigarettes smoked per day on weekends.\n",
    "11) 'amt_weekdays' (integer) : Number of cigarettes smoked per day on weekdays.\n",
    "12) 'type' (string) : Type of cigarettes smoked with levels Packets, Hand-Rolled, Both/Mainly Packets and Both/Mainly Hand-Rolled \n",
    "\"\"\"\n",
    "\n",
    "task_request = \"Suggest some data analysis questions we could get answers from this data.\"\n",
    "\n",
    "\n",
    "initial_message = [\n",
    "    SystemMessage(content = system_message),\n",
    "    HumanMessage(content=f\"{data_brief}\\n\\n{task_request}\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ChatOpenAI object. Assign to chat.\n",
    "chat = ChatOpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "# Pass your message to GPT. Assign to rsps_suggest_questions.\n",
    "intial_response = chat(initial_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are some data analysis questions you could explore using the provided dataset on smoking habits in the UK:\n",
       "\n",
       "1. What is the overall prevalence of smoking among the surveyed population?\n",
       "2. How does smoking prevalence vary by gender?\n",
       "3. Are there significant differences in smoking prevalence across different age groups?\n",
       "4. Does marital status have an impact on smoking behaviour?\n",
       "5. Is there a relationship between the highest level of education attained and smoking status?\n",
       "6. How does nationality influence smoking habits?\n",
       "7. Are there differences in smoking prevalence among various ethnic groups?\n",
       "8. Does gross income level correlate with smoking behaviour?\n",
       "9. Which region has the highest and lowest rates of smoking?\n",
       "10. What is the average number of cigarettes smoked per day on weekends and weekdays?\n",
       "11. What are the most commonly smoked types of cigarettes among smokers?\n",
       "12. Is there a correlation between the type of cigarettes smoked and the amount smoked per day?\n",
       "\n",
       "By analyzing these questions, you can gain insights into the demographic characteristics of smokers, patterns of tobacco consumption, and potential factors influencing smoking behaviours. These insights can inform the development of targeted government policies aimed at reducing smoking rates in the UK."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(intial_response.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
